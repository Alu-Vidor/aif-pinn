# AIF-PINN Framework

High-order asymptotic priors significantly improve the accuracy and robustness of physics-informed neural networks (PINNs) for stiff single-parameter fractional differential equations (SPFDEs). The Asymptotically-Informed PINN (AIF-PINN) framework in this repository packages these ideas into a reusable toolkit that combines fractional calculus operators, asymptotic embeddings, and modern training orchestration.

## Key Capabilities
- Fractional Caputo derivative discretization via the dense L1 scheme with automatic validation of the collocation grid.
- PINN architectures that inject Mittag-Leffler asymptotics, enforce hard boundary conditions, and optionally solve inverse problems by estimating the fractional order and relaxation parameter.
- Hybrid optimization schedule (Adam warm-up followed by L-BFGS refinement) with reproducible seeding and optional `torch.compile` acceleration.
- Data generation utilities that bias collocation points toward boundary layers for stiff problems.
- Baseline finite-difference solvers and comparison scripts to quantify gains over classical numerical schemes.
- Ready-to-run studies for benchmark SPFDEs, noisy inverse identification, and an applied business case (fractional advertising goodwill).

## Project Architecture
| Module | Responsibility |
| --- | --- |
| `aif_pinn/problem.py` | Abstract SPFDE definition shared by solvers and scripts. |
| `aif_pinn/problems_zoo.py` | Benchmark problems (linear relaxation, variable-coefficient, nonlinear logistic). |
| `aif_pinn/data.py` | Collocation grid generator with log-uniform refinement near boundary layers. |
| `aif_pinn/operators.py` | Caputo fractional derivative matrix assembly and application. |
| `aif_pinn/mittag.py` | Piecewise approximation of the Mittag-Leffler function for feature embeddings. |
| `aif_pinn/model.py` | AIF-PINN neural architecture with asymptotic features and hard constraints. |
| `aif_pinn/solver.py` | Training harness implementing the Adam → L-BFGS optimization pipeline. |
| `aif_pinn/fdm_solver.py` | Finite-difference baselines and helper to solve variable-coefficient linear problems. |
| `run_experiment.py` | Reference CLI for training and visualizing benchmark solutions. |
| `inverse_problem.py` | Demonstration of parameter identification (recovering `alpha` and `epsilon`). |
| `business_test.py` | Business case study with seasonal drivers and KPI-style reporting. |

## Requirements and Installation
1. Python 3.10 or newer.
2. PyTorch 2.0+, NumPy, and Matplotlib. Install the CPU stack with:
   ```bash
   pip install torch numpy matplotlib
   ```
   GPU builds of PyTorch can be installed from https://pytorch.org if desired.
3. (Optional) JAX is only needed when calling `DataGenerator.to_jax`.

When working inside a virtual environment:
```bash
python -m venv .venv
.venv\Scripts\activate
pip install --upgrade pip
pip install torch numpy matplotlib
```

## Quick Start: Benchmark Experiment
Train AIF-PINN on one of the packaged problems and persist a figure:
```bash
python run_experiment.py \
    --problem linear \
    --num-collocation 512 \
    --adam-steps 3000 \
    --lbfgs-iter 2000 \
    --epsilon 0.05 \
    --horizon 5.0 \
    --output figures/aif_pinn_benchmark.png
```

Important CLI arguments:
- `--problem {linear,variable,logistic}` selects the benchmark formulation.
- `--num-collocation` controls the size of the collocation grid generated by `DataGenerator`.
- `--adam-steps`, `--adam-lr`, `--lbfgs-iter` tune the optimization phases.
- `--alpha`, `--epsilon`, `--initial-condition`, `--horizon` override physical parameters.
- `--device` chooses the PyTorch device (`cpu`, `cuda:0`, …); `--compile` toggles `torch.compile`.
- `--output` and `--no-show` configure figure export without opening a GUI window.

The script prints the training loss trace and produces a comparison plot in `figures/`.

## Extended Workflows
- **Inverse identification**: `python inverse_problem.py --num-observations 80 --num-collocation 512 --physics-weight 1e-3` fits `alpha` and `epsilon` jointly with the state trajectory from noisy data.
- **Business case**: `python business_test.py --campaign-level 1.5 --seasonal-amplitude 0.4` runs the advertising goodwill scenario, compares to finite-difference baselines, and exports multi-panel reports under `figures/`.
- **Benchmark comparisons**: `benchmark_comparison.py`, `compare_methods.py`, and `compare_variable.py` sweep hyper-parameters, log performance metrics, and save reproducible figures to support ablation studies.

Each CLI exposes `--help` for an exhaustive list of domain-specific options (e.g., forcing amplitudes, observation noise, KPI break-downs).

## Using AIF-PINN as a Library
Every component is importable and composable:
```python
from aif_pinn import (
    LinearRelaxationProblem,
    DataGenerator,
    FractionalDerivativeOperator,
    AIFPINNModel,
    PINNSolver,
)

problem = LinearRelaxationProblem(alpha=0.7, epsilon=0.02, horizon=3.0)
grid = DataGenerator(problem).generate_grid(num_points=256)
operator = FractionalDerivativeOperator(grid, problem.alpha, dtype=torch.float32, device="cuda:0")
model = AIFPINNModel(alpha=problem.alpha, epsilon=problem.epsilon, initial_condition=problem.initial_condition)
solver = PINNSolver(model, operator, problem, device=torch.device("cuda:0"))
history = solver.train(adam_steps=2000, lbfgs_max_iter=1000, verbose=True)
```

To customize for a new SPFDE, subclass `AbstractSPFDE`, implement `residual`, and optionally override `exact_solution`, `reaction_coefficient`, or `forcing`. The fractional derivative operator and solver will consume the new problem automatically.

## Repository Layout
```
aif-pinn/
├─ aif_pinn/             # Core framework modules described above
├─ figures/              # Generated plots (ignored by Git)
├─ compare_methods.py    # Ablations over solver configurations
├─ compare_variable.py   # Experiments with variable coefficients
├─ benchmark_comparison.py
├─ business_test.py      # Business case CLI
├─ inverse_problem.py    # Inverse problem CLI
├─ run_experiment.py     # Benchmark runner
└─ README.md
```

## Development Notes
- Set the random seed via the available CLI flags to reproduce published figures.
- Prefer `rg`/`pytest`/`python -m` style invocations when extending experiments.
- The repo currently relies on manual testing through the benchmark scripts; add unit tests under a `tests/` package if you contribute new numerical components.
- When contributing, run your chosen experiment scripts and keep regenerated figures under `figures/` for reference.

## License

This project is licensed under the MIT License. See `LICENSE` for the full text.
